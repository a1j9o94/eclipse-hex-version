function ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); keys.push.apply(keys, symbols); } return keys; }

function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { ownKeys(Object(source), true).forEach(function (key) { _defineProperty(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

import { useType } from "@hex-engine/core";
import { useUpdate } from "../Hooks";
import { useAudioContext } from "./AudioContext";
import { makeModalSynthesis } from "modal-synthesis";

/**
 * A Component that can be used to generate procedural sound effects,
 * by synthesizing modal sounds. A modal sound is a resonating, ringing
 * sound that is composed out of several different sine waves, such as
 * the sound that is emitted when you strike a wine glass or metal rod.
 *
 * If you use a spectrogram to identify the frequency, amplitude, and decay rate
 * of the sine waves that the sound is made out of, then you can provide them
 * to this function, and it will create a model that synthesizes that sound.
 *
 * If you then vary the frequency, amplitude, or decay rate slightly each time
 * the sound is played, you can get a rich bank of sound effects all from one sound.
 */
export default function ProceduralSfx(modes) {
  useType(ProceduralSfx);
  var synthesis = null;
  useUpdate(function () {
    if (!synthesis) {
      var audioContext = useAudioContext();
      if (!audioContext) return; // Can't play audio until first user interaction with the page

      synthesis = makeModalSynthesis(modes, audioContext);
    }
  });
  var hasWarned = false;
  return {
    /**
     * Returns the synthesis model, if it is available.
     *
     * To work around browsers disallowing sound to be played without the user interacting with
     * the page first, the synthesis model will not be created until the first time the user
     * clicks on the page, or presses a key. Until then, this will be `null`.
     */
    get synthesis() {
      return synthesis;
    },

    /**
     * Synthesize a sound effect. You can optionally include
     * `amplitudeMultiplier`, `frequencyMultiplier`, or `decayMultiplier`
     * values to vary the waves, which may be desirable to, for example,
     * vary the loudness based on the speed of two colliding objects.
     *
     * Even if you do not have any variables like speed to connect to
     * your sounds, it is recommended that you vary the waves slightly each
     * time the sound is played, to give the sound some variety.
     */
    play: function play(options) {
      var _ref;

      if (!synthesis) {
        if (!hasWarned) {
          console.warn("Tried to play a sound from ProceduralSfx, but the synthesis wasn't ready yet. " + "This usually means that the user hasn't interacted with the page yet, " + "so the webpage isn't allowed to play audio yet, but it *could* mean that " + "there is no AudioContext component on your root entity. If you have clicked on the page " + "and still don't hear audio, please check to ensure there is an AudioContext component " + "on the root entity. ");
          hasWarned = true;
        }

        return;
      }

      var audioContext = useAudioContext();
      if (!audioContext) return; // Can't play audio until first user interaction with the page

      var model = synthesis.makeModel(_objectSpread({}, options, {
        autoDisconnect: true
      }));
      model.outputNode.connect(audioContext.destination);
      model.excite((_ref = options === null || options === void 0 ? void 0 : options.whiteNoiseDuration) !== null && _ref !== void 0 ? _ref : 10);
    }
  };
}